{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_classification(dataset, threshold_factor=1.0):\n",
    "    data = pd.read_csv(dataset)\n",
    "    \n",
    "    # Remove duplicate attributes\n",
    "    data.drop([\"suicides_no\", \"population\", \"country-year\", \"gdp_for_year ($)\"], axis=1, inplace=True)\n",
    "    data.drop(\"HDI for year\", axis=1, inplace=True)\n",
    "    \n",
    "    # Remove 'years' text from 'age' and convert age strings to integers\n",
    "    data[\"age\"] = data[\"age\"].str.strip(\" years\")\n",
    "    def convert_age(age):\n",
    "        if '75+' in age:\n",
    "            return 80\n",
    "        elif '55-74' in age:\n",
    "            return 65\n",
    "        elif '35-54' in age:\n",
    "            return 45\n",
    "        elif '25-34' in age:\n",
    "            return 30\n",
    "        elif '15-24' in age:\n",
    "            return 20\n",
    "        elif '5-14' in age:\n",
    "            return 10\n",
    "        else:\n",
    "            return None\n",
    "    data['age'] = data['age'].apply(convert_age)\n",
    "    \n",
    "    # Encode sex using a mapping\n",
    "    sex_mapping = {'female': 0, 'male': 1}\n",
    "    data['sex'] = data['sex'].map(sex_mapping)\n",
    "    \n",
    "    # Apply one-hot encoding to 'generation'\n",
    "    data = pd.get_dummies(data, columns=['generation'])\n",
    "    \n",
    "    # Calculate the mean suicide rate and adjust by the threshold_factor\n",
    "    mean_suicide_rate = data[\"suicides/100k pop\"].mean()\n",
    "    adjusted_threshold = mean_suicide_rate * threshold_factor\n",
    "\n",
    "    # Create a new attribute, Over_threshold_suicides\n",
    "    # 1 if the suicide rate is higher than the adjusted threshold, 0 otherwise\n",
    "    data[\"Over_threshold_suicides\"] = np.where(data[\"suicides/100k pop\"] > adjusted_threshold, 1, 0)\n",
    "    \n",
    "    # Perform target encoding using KFold for 'country'\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=33)\n",
    "    data['country_encoded'] = 0.0\n",
    "    for train_index, val_index in kf.split(data):\n",
    "        train_fold, val_fold = data.iloc[train_index], data.iloc[val_index]\n",
    "        mean_encoded = train_fold.groupby('country')['suicides/100k pop'].mean()\n",
    "        data.loc[val_index, 'country_encoded'] = val_fold['country'].map(mean_encoded)\n",
    "    \n",
    "    # Fill missing 'country_encoded' values with global mean\n",
    "    global_mean = data['suicides/100k pop'].mean()\n",
    "    data['country_encoded'].fillna(global_mean, inplace=True)\n",
    "    \n",
    "    # Remove the original 'country' column\n",
    "    data.drop(columns=['country'], inplace=True)\n",
    "    \n",
    "    # Split the dataset into training and testing datasets\n",
    "    train_data, test_data = train_test_split(data, test_size=0.3, random_state=33)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\"suicides/100k pop\", \"Over_threshold_suicides\"]\n",
    "    X_train = train_data.drop(columns=columns_to_drop)\n",
    "    Y_train = train_data[\"Over_threshold_suicides\"]\n",
    "    X_test = test_data.drop(columns=columns_to_drop)\n",
    "    Y_test = test_data[\"Over_threshold_suicides\"]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Weights:\n",
      "test_accuracy: 0.08\n",
      "precision: 0.23\n",
      "recall: 0.23\n",
      "f1_positive: 0.08\n",
      "f1_negative: 0.31\n",
      "cv_accuracy: 0.08\n"
     ]
    }
   ],
   "source": [
    "def adjust_weights(weights):\n",
    "    # Calculate the sum of all provided weights\n",
    "    total = sum(weights.values())\n",
    "    \n",
    "    # Normalize each weight by dividing by the total sum to adjust their proportions\n",
    "    adjusted_weights = {key: value / total for key, value in weights.items()}\n",
    "    \n",
    "    return adjusted_weights\n",
    "\n",
    "# Example weights input from the user\n",
    "input_weights = {\n",
    "    'test_accuracy': 1,  # Weight for test accuracy\n",
    "    'precision': 3,      # Weight for precision\n",
    "    'recall': 3,         # Weight for recall\n",
    "    'f1_positive': 1,    # Weight for F1 score of the positive class\n",
    "    'f1_negative' : 4,   # Weight for F1 score of the negative class\n",
    "    'cv_accuracy': 1     # Weight for cross-validation accuracy\n",
    "}\n",
    "\n",
    "# Adjust the weights to ensure their sum equals 1\n",
    "WEIGHTS = adjust_weights(input_weights)\n",
    "\n",
    "# Print the adjusted weights\n",
    "print(\"Adjusted Weights:\")\n",
    "for key, value in WEIGHTS.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logistic_regression(X_train, Y_train, X_test, Y_test):\n",
    "    # Create a logistic regression pipeline with feature scaling\n",
    "    logreg = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs', max_iter=1000))\n",
    "    logreg.fit(X_train, Y_train)  # Train the model\n",
    "    \n",
    "    # Make predictions and calculate accuracy on the test set\n",
    "    Y_pred_test = logreg.predict(X_test)\n",
    "    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n",
    "\n",
    "    # Compute precision and recall for the model using macro averaging\n",
    "    precision = precision_score(Y_test, Y_pred_test, average='macro')\n",
    "    recall = recall_score(Y_test, Y_pred_test, average='macro')\n",
    "    \n",
    "    # Compute F1 scores for each class and extract separately\n",
    "    f1_scores = f1_score(Y_test, Y_pred_test, average=None)\n",
    "    f1_positive, f1_negative = f1_scores[0], f1_scores[1]\n",
    "    \n",
    "    # Conduct 10-fold cross-validation to estimate model stability\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=33)\n",
    "    cv_accuracy = cross_val_score(logreg, X_train, Y_train, cv=kf, scoring='accuracy').mean()\n",
    "    \n",
    "    # Calculate integrated score using weighted averages from WEIGHTS\n",
    "    integrated_score = (\n",
    "        test_accuracy * WEIGHTS['test_accuracy'] +\n",
    "        precision * WEIGHTS['precision'] +\n",
    "        recall * WEIGHTS['recall'] +\n",
    "        f1_positive * WEIGHTS['f1_positive'] +\n",
    "        f1_negative * WEIGHTS['f1_negative'] +\n",
    "        cv_accuracy * WEIGHTS['cv_accuracy']\n",
    "    )\n",
    "    \n",
    "    return integrated_score * 100 # Convert to percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_decision_tree(X_train, Y_train, X_test, Y_test):\n",
    "    # Initialize and train a Decision Tree model\n",
    "    decision_tree = DecisionTreeClassifier(random_state=33)\n",
    "    decision_tree.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict and evaluate accuracy on both training and test sets\n",
    "    Y_pred_test = decision_tree.predict(X_test)\n",
    "    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n",
    "\n",
    "    # Calculate precision and recall using macro averaging to treat all classes equally\n",
    "    precision = precision_score(Y_test, Y_pred_test, average='macro', zero_division=0)\n",
    "    recall = recall_score(Y_test, Y_pred_test, average='macro', zero_division=0)\n",
    "    \n",
    "    # Compute F1 scores for positive and negative classes individually\n",
    "    f1_scores = f1_score(Y_test, Y_pred_test, average=None)\n",
    "    f1_positive, f1_negative = f1_scores[0], f1_scores[1]  # F1 scores for class 0 and class 1\n",
    "    \n",
    "    # Perform 10-fold cross-validation to estimate model robustness\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=33)\n",
    "    cv_accuracy = cross_val_score(decision_tree, X_train, Y_train, cv=kf, scoring='accuracy').mean()\n",
    "    \n",
    "    # Calculate an integrated score based on predefined weights\n",
    "    integrated_score = (test_accuracy * WEIGHTS['test_accuracy'] +\n",
    "                        precision * WEIGHTS['precision'] +\n",
    "                        recall * WEIGHTS['recall'] +\n",
    "                        f1_positive * WEIGHTS['f1_positive'] +\n",
    "                        f1_negative * WEIGHTS['f1_negative'] +\n",
    "                        cv_accuracy * WEIGHTS['cv_accuracy'])\n",
    "\n",
    "    return integrated_score * 100 # Convert to percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_knn(X_train, Y_train, X_test, Y_test):\n",
    "    # Initialize and train a K-Nearest Neighbors model with 3 neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict and evaluate accuracy on both training and test sets\n",
    "    Y_pred_train = knn.predict(X_train)\n",
    "    Y_pred_test = knn.predict(X_test)\n",
    "    train_accuracy = accuracy_score(Y_train, Y_pred_train)\n",
    "    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n",
    "\n",
    "    # Calculate precision, recall, and F1 scores using macro averaging\n",
    "    precision = precision_score(Y_test, Y_pred_test, average='macro')\n",
    "    recall = recall_score(Y_test, Y_pred_test, average='macro')\n",
    "    \n",
    "    # Compute F1 scores for positive and negative classes individually\n",
    "    f1_scores = f1_score(Y_test, Y_pred_test, average=None)\n",
    "    f1_positive, f1_negative = f1_scores[0], f1_scores[1]  # F1 scores for class 0 and class 1\n",
    "\n",
    "    # Perform 10-fold cross-validation to estimate model robustness\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=33)\n",
    "    cv_accuracy = cross_val_score(knn, X_train, Y_train, cv=kf, scoring='accuracy').mean()\n",
    "\n",
    "    # Calculate an integrated score based on predefined weights\n",
    "    integrated_score = (test_accuracy * WEIGHTS['test_accuracy'] +\n",
    "                        precision * WEIGHTS['precision'] +\n",
    "                        recall * WEIGHTS['recall'] +\n",
    "                        f1_positive * WEIGHTS['f1_positive'] +\n",
    "                        f1_negative * WEIGHTS['f1_negative'] +\n",
    "                        cv_accuracy * WEIGHTS['cv_accuracy'])\n",
    "\n",
    "    return integrated_score * 100 # Convert to percentage     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gaussian_nb(X_train, Y_train, X_test, Y_test):\n",
    "    # Initialize and train Gaussian Naive Bayes model\n",
    "    gaussian = GaussianNB()\n",
    "    gaussian.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test set and calculate accuracy\n",
    "    Y_pred_test = gaussian.predict(X_test)\n",
    "    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score using macro averaging\n",
    "    precision = precision_score(Y_test, Y_pred_test, average='macro', zero_division=0)\n",
    "    recall = recall_score(Y_test, Y_pred_test, average='macro', zero_division=0)\n",
    "    \n",
    "    # Compute F1 scores for positive and negative classes individually\n",
    "    f1_scores = f1_score(Y_test, Y_pred_test, average=None)\n",
    "    f1_positive, f1_negative = f1_scores[0], f1_scores[1]  # F1 scores for class 0 and class 1\n",
    "\n",
    "    # Perform 10-fold cross-validation to estimate the model's robustness\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=33)\n",
    "    cv_accuracy = cross_val_score(gaussian, X_train, Y_train, cv=kf, scoring='accuracy').mean()\n",
    "\n",
    "    # Calculate an integrated score based on predefined weights\n",
    "    integrated_score = (test_accuracy * WEIGHTS['test_accuracy'] +\n",
    "                        precision * WEIGHTS['precision'] +\n",
    "                        recall * WEIGHTS['recall'] +\n",
    "                        f1_positive * WEIGHTS['f1_positive'] +\n",
    "                        f1_negative * WEIGHTS['f1_negative'] +\n",
    "                        cv_accuracy * WEIGHTS['cv_accuracy'])\n",
    "\n",
    "    return integrated_score * 100  # Convert to percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_forest(X_train, Y_train, X_test, Y_test):\n",
    "    # Initialize and train a Random Forest classifier\n",
    "    random_forest = RandomForestClassifier(n_estimators=100, random_state=33)\n",
    "    random_forest.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict and evaluate metrics on both training and test sets\n",
    "    Y_pred_test = random_forest.predict(X_test)\n",
    "    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n",
    "\n",
    "    # Calculate precision, recall, and F1 scores using macro averaging\n",
    "    precision = precision_score(Y_test, Y_pred_test, average='macro')\n",
    "    recall = recall_score(Y_test, Y_pred_test, average='macro')\n",
    "    \n",
    "    # Compute F1 scores for positive and negative classes individually\n",
    "    f1_scores = f1_score(Y_test, Y_pred_test, average=None)\n",
    "    f1_positive, f1_negative = f1_scores[0], f1_scores[1]  # F1 scores for class 0 and class 1\n",
    "\n",
    "    # Perform 10-fold cross-validation to estimate model robustness\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=33)\n",
    "    cv_accuracy = cross_val_score(random_forest, X_train, Y_train, cv=kf, scoring='accuracy').mean()\n",
    "\n",
    "    # Calculate an integrated score based on predefined weights\n",
    "    integrated_score = (test_accuracy * WEIGHTS['test_accuracy'] +\n",
    "                        precision * WEIGHTS['precision'] +\n",
    "                        recall * WEIGHTS['recall'] +\n",
    "                        f1_positive * WEIGHTS['f1_positive'] +\n",
    "                        f1_negative * WEIGHTS['f1_negative'] +\n",
    "                        cv_accuracy * WEIGHTS['cv_accuracy'])\n",
    "\n",
    "    return integrated_score * 100  # Convert to percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n",
      "C:\\TempFolder\\ipykernel_5640\\912627693.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country_encoded'].fillna(global_mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.70000\n",
      "\tIntegrated Score - 89.12256\n",
      "\n",
      "Rank 2:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.75000\n",
      "\tIntegrated Score - 88.93362\n",
      "\n",
      "Rank 3:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.55000\n",
      "\tIntegrated Score - 88.90082\n",
      "\n",
      "Rank 4:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.00000\n",
      "\tIntegrated Score - 88.83696\n",
      "\n",
      "Rank 5:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.60000\n",
      "\tIntegrated Score - 88.77400\n",
      "\n",
      "Rank 6:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.50000\n",
      "\tIntegrated Score - 88.69644\n",
      "\n",
      "Rank 7:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.95000\n",
      "\tIntegrated Score - 88.63702\n",
      "\n",
      "Rank 8:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.65000\n",
      "\tIntegrated Score - 88.63049\n",
      "\n",
      "Rank 9:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.05000\n",
      "\tIntegrated Score - 88.12560\n",
      "\n",
      "Rank 10:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.80000\n",
      "\tIntegrated Score - 88.11487\n",
      "\n",
      "Rank 11:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.90000\n",
      "\tIntegrated Score - 87.81475\n",
      "\n",
      "Rank 12:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.20000\n",
      "\tIntegrated Score - 87.80424\n",
      "\n",
      "Rank 13:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.10000\n",
      "\tIntegrated Score - 87.79540\n",
      "\n",
      "Rank 14:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 0.85000\n",
      "\tIntegrated Score - 87.69377\n",
      "\n",
      "Rank 15:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.15000\n",
      "\tIntegrated Score - 87.65769\n",
      "\n",
      "Rank 16:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.25000\n",
      "\tIntegrated Score - 87.48217\n",
      "\n",
      "Rank 17:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.45000\n",
      "\tIntegrated Score - 87.34312\n",
      "\n",
      "Rank 18:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.30000\n",
      "\tIntegrated Score - 87.33293\n",
      "\n",
      "Rank 19:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.50000\n",
      "\tIntegrated Score - 86.98889\n",
      "\n",
      "Rank 20:\n",
      "\tModel - Decision Tree\n",
      "\tThreshold Factor - 1.40000\n",
      "\tIntegrated Score - 86.88233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, dataset, models, threshold_factors, top_n=5):\n",
    "        self.dataset = dataset\n",
    "        self.models = models\n",
    "        self.threshold_factors = threshold_factors\n",
    "        self.top_n = top_n\n",
    "\n",
    "    def evaluate_models(self):\n",
    "        results = []\n",
    "        for threshold in self.threshold_factors:\n",
    "            X_train, Y_train, X_test, Y_test = preprocess_classification(self.dataset, threshold)\n",
    "            for model_name, model_func in self.models.items():\n",
    "                score = model_func(X_train, Y_train, X_test, Y_test)\n",
    "                results.append({\n",
    "                    'model': model_name,\n",
    "                    'threshold': threshold,\n",
    "                    'score': score\n",
    "                })\n",
    "        # Sorting and returning top n results\n",
    "        return sorted(results, key=lambda x: x['score'], reverse=True)[:self.top_n]\n",
    "\n",
    "# Model functions need to be defined elsewhere in the script or as imports\n",
    "\n",
    "# Configuration\n",
    "dataset_path = 'master.csv'\n",
    "threshold_range = np.linspace(0.5, 1.5, 21)  # Range of thresholds from 0.5 to 1.5\n",
    "top_results_count = 20  # Number of top models to return\n",
    "\n",
    "# Dictionary of models to evaluate\n",
    "models_to_evaluate = {\n",
    "    'Logistic Regression': evaluate_logistic_regression,\n",
    "    'Decision Tree': evaluate_decision_tree,\n",
    "\n",
    "}\n",
    "\n",
    "# Creating an instance of the evaluator\n",
    "evaluator = ModelEvaluator(dataset_path, models_to_evaluate, threshold_range, top_results_count)\n",
    "best_models = evaluator.evaluate_models()\n",
    "\n",
    "# Display results\n",
    "for idx, result in enumerate(best_models, start=1):\n",
    "    print(f\"Rank {idx}:\")\n",
    "    print(f\"\\tModel - {result['model']}\")\n",
    "    print(f\"\\tThreshold Factor - {result['threshold']:.5f}\")\n",
    "    print(f\"\\tIntegrated Score - {result['score']:.5f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
